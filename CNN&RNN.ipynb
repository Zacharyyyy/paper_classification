{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2989,
     "status": "ok",
     "timestamp": 1577959348911,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "ErD8HMdgIWRv",
    "outputId": "6f812bae-0644-4b09-fc4e-0a64568ad4df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Activation, Conv1D, Dense, Embedding, Flatten, Input, MaxPooling1D, Dropout, Input, Bidirectional, GlobalMaxPool1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import categorical_accuracy, binary_accuracy\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from collections import Counter\n",
    "import gc\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, BatchNormalization\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from tensorflow.keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 335563,
     "status": "ok",
     "timestamp": 1577959133461,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "W5BqkIDMIfld",
    "outputId": "a3cfaa18-ce93-4048-ede6-25b7a50dfec3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-ffd8ee6c-b624-45e6-ad66-32905d90c265\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-ffd8ee6c-b624-45e6-ad66-32905d90c265\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data.csv to data.csv\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6471,
     "status": "ok",
     "timestamp": 1576513881842,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "j5RB7P9QJ08D",
    "outputId": "769291b4-0b3d-480d-985a-42b59741db20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2.0.zip  fastText-0.2.0  glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
      "data.csv   fast.zip\t   glove.6B.200d.txt  glove.6B.50d.txt\t sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQxZ3yoOKh7B"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(pd.read_csv('data.csv', encoding = \"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1577959354787,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "N_jXSlANNLSl",
    "outputId": "8338b0a2-ec11-4a9d-bcb3-0476a5c3dea0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>THEORETICAL</th>\n",
       "      <th>ENGINEERING</th>\n",
       "      <th>EMPIRICAL</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rapid popularity of Internet of Things (IoT) a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A Brain-Inspired Trust Management Model to Ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this paper, we address the problem of compu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>On Efficient Computation of Shortest Dubins Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>High quality upsampling of sparse 3D point clo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data-driven Upsampling of Point Clouds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Internet is the main source of information now...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Accessibility or Usability of InteractSE? A He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automated Facial Expression Recognition (FER) ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Spatio-Temporal Facial Expression Recognition ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  ...                                              Title\n",
       "0  Rapid popularity of Internet of Things (IoT) a...  ...  A Brain-Inspired Trust Management Model to Ass...\n",
       "1  In this paper, we address the problem of compu...  ...  On Efficient Computation of Shortest Dubins Pa...\n",
       "2  High quality upsampling of sparse 3D point clo...  ...             Data-driven Upsampling of Point Clouds\n",
       "3  Internet is the main source of information now...  ...  Accessibility or Usability of InteractSE? A He...\n",
       "4  Automated Facial Expression Recognition (FER) ...  ...  Spatio-Temporal Facial Expression Recognition ...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZFete6GcNggS"
   },
   "source": [
    "# abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1601,
     "status": "ok",
     "timestamp": 1577959358034,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "NmX7NazLN9E9",
    "outputId": "570775b1-1584-420f-9472-f9746cd47ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQ9j84zPNdkY"
   },
   "outputs": [],
   "source": [
    "texts = data['Abstract']\n",
    "texts = texts.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1577959358872,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "pr-3GVhcMMGB",
    "outputId": "5333df8f-f164-4a47-bb85-134a922d3f15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rapid popularity of internet of things (iot) and cloud computing permits neuroscientists to collect multilevel and multichannel brain data to better understand brain functions, diagnose diseases, and devise treatments.$$$to ensure secure and reliable data communication between end-to-end (e2e) devices supported by current iot and cloud infrastructure, trust management is needed at the iot and user ends.$$$this paper introduces a neuro-fuzzy based brain-inspired trust management model (tmm) to secure iot devices and relay nodes, and to ensure data reliability.$$$the proposed tmm utilizes node behavioral trust and data trust estimated using adaptive neuro-fuzzy inference system and weighted-additive methods respectively to assess the nodes trustworthiness.$$$in contrast to the existing fuzzy based tmms, the ns2 simulation results confirm the robustness and accuracy of the proposed tmm in identifying malicious nodes in the communication network.$$$with the growing usage of cloud based iot frameworks in neuroscience research, integrating the proposed tmm into the existing infrastructure will assure secure and reliable data communication among the e2e devices.'"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HManT9etP3D9"
   },
   "outputs": [],
   "source": [
    "for i in range(len(texts)):\n",
    "  str = texts[i]\n",
    "  texts[i] = str.replace('$$$', '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hevegadP3HE"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "for c in string.punctuation:\n",
    "    texts = texts.str.replace(c, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFXaZxtdZlXz"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(texts)):\n",
    "    token = word_tokenize(texts[i]) \n",
    "    temp = [w for w in token if not w in stop_words]\n",
    "    texts[i] = \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 22113,
     "status": "ok",
     "timestamp": 1577959385163,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "RDz6-f8bJc6i",
    "outputId": "763697cf-e936-4dd3-8521-cb725e26389e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rapid popularity internet things iot cloud computing permits neuroscientists collect multilevel multichannel brain data better understand brain functions diagnose diseases devise treatments ensure secure reliable data communication end end e2e devices supported current iot cloud infrastructure trust management needed iot user ends paper introduces neuro fuzzy based brain inspired trust management model tmm secure iot devices relay nodes ensure data reliability proposed tmm utilizes node behavioral trust data trust estimated using adaptive neuro fuzzy inference system weighted additive methods respectively assess nodes trustworthiness contrast existing fuzzy based tmms ns2 simulation results confirm robustness accuracy proposed tmm identifying malicious nodes communication network growing usage cloud based iot frameworks neuroscience research integrating proposed tmm existing infrastructure assure secure reliable data communication among e2e devices\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27630,
     "status": "ok",
     "timestamp": 1575875815540,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "ip1XVv3Fg83F",
    "outputId": "5a0360a9-b34f-4770-9229-6495b9927b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(texts)):\n",
    "    input_str = word_tokenize(texts[i])\n",
    "    for j in range(len(input_str)):\n",
    "        input_str[j] = lemmatizer.lemmatize(input_str[j])\n",
    "    texts[i] = \" \".join(input_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QFJVFGEqP-0X"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(texts)):\n",
    "    input_str = word_tokenize(texts[i])\n",
    "    for j in range(len(input_str)):\n",
    "        input_str[j] = stemmer.stem(input_str[j])\n",
    "    texts[i] = \" \".join(input_str)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9BDyEHAjIWOb"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(texts)):\n",
    "    texts[i] = re.sub(r'\\b\\d+\\b *|\\b[a-z]\\b *', '', texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1513,
     "status": "ok",
     "timestamp": 1577959393128,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "TNm8vVUuO3LA",
    "outputId": "409f8c2a-3df2-4abc-a632-2ae30867d9fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'internet main source information nowadays search engines must various alternative manners search results representation representation methods enable end users especially visually impaired vi web searchers access information web aim paper design evaluate improve interface vi users perform search browse results attempt provides new accessibility tool vi web searchers conceptual modelling technique proposed paper based formal concept analysis fca hides detailed information collected data results approach highlights main discovered concepts focused combined context interactive navigation interface called interactive search engine interactse minimize time effort required vi users standardised set guidelines heuristics used evaluation usability accessibility aspects interface therefore interactse evaluated experts using nielsen heuristics web content accessibility guidelines wcag terms usability accessibility analysis carried based number usability problems identified average severity ratings results show frequently violated heuristics nielsen set consistency documentation average severity rating problems found using nielsen set minor results also show frequently violated wcag guidelines distinguishable followed navigable affordance average severity rating problems found using wcag guidelines also minor results show nielsen heuristics wcag guidelines contributed identifying number usability problems'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BufAP5KXO7hk"
   },
   "outputs": [],
   "source": [
    "vocab_size = 50709\n",
    "\n",
    "tokenizer = Tokenizer(num_words=vocab_size) # Setup tokenizer\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts) # Generate sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 642,
     "status": "ok",
     "timestamp": 1577717169749,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "js-rBCHYO7m1",
    "outputId": "00d9cbb4-939b-4174-d5bd-cfea71a08cd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50,709 unique words.\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print('Found {:,} unique words.'.format(len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1576514530621,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "bu9WJcfSlqJT",
    "outputId": "c09f6ac5-96c6-4da4-d200-880cbf3ce8ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61477"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 658,
     "status": "ok",
     "timestamp": 1577959500030,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "wd3bpYh4PDcl",
    "outputId": "32c87044-1357-448a-f2f1-74db27e412c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94.13533333333334, 35.595171068662815)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the average length of a text\n",
    "avg = sum(map(len, word_sequences)) / len(word_sequences)\n",
    "\n",
    "# Get the standard deviation of the sequence length\n",
    "std = np.sqrt(sum(map(lambda x: (len(x) - avg)**2, word_sequences)) / len(word_sequences))\n",
    "\n",
    "avg,std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8HPHiwAWPDgE"
   },
   "outputs": [],
   "source": [
    "max_length = 140\n",
    "abstract = pad_sequences(sequences, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jIuD4qWPDkW"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "sentences = []\n",
    "for i in range(len(texts)):\n",
    "    sentences.append(word_tokenize(texts[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TgDoAHk7oM-h"
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 167263,
     "status": "ok",
     "timestamp": 1577959331252,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "0elMaVjtojs9",
    "outputId": "ae16dfc3-c780-42dd-ca4f-60d9c1ea12c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_lg==2.1.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
      "\u001b[K     |████████████████████████████████| 826.9MB 93.2MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
      "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255076 sha256=06eb28fa38db786a236aeed6629eaaf0e4400ef3edb66d05617eb38de76fa47f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-n6ufqx8x/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
      "Successfully built en-core-web-lg\n",
      "Installing collected packages: en-core-web-lg\n",
      "Successfully installed en-core-web-lg-2.1.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 35502,
     "status": "ok",
     "timestamp": 1577959458071,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "ixuZEWb7oOtQ",
    "outputId": "6f1837b6-1191-42e9-9e38-5376bf454649"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27000it [00:21, 1229.84it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "text_list = texts\n",
    "nlp = spacy.load('en_core_web_lg', disable=['parser','ner','tagger'])\n",
    "nlp.vocab.add_flag(lambda s: s.lower() in spacy.lang.en.stop_words.STOP_WORDS, spacy.attrs.IS_STOP)\n",
    "word_dict = {}\n",
    "word_index = 1\n",
    "lemma_dict = {}\n",
    "docs = nlp.pipe(text_list, n_threads = 2)\n",
    "word_sequences = []\n",
    "for doc in tqdm(docs):\n",
    "    word_seq = []\n",
    "    for token in doc:\n",
    "        if (token.text not in word_dict) and (token.pos_ is not \"PUNCT\"):\n",
    "            word_dict[token.text] = word_index\n",
    "            word_index += 1\n",
    "            lemma_dict[token.text] = token.lemma_\n",
    "        if token.pos_ is not \"PUNCT\":\n",
    "            word_seq.append(word_dict[token.text])\n",
    "    word_sequences.append(word_seq)\n",
    "del docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5ICoVh4M5m6"
   },
   "outputs": [],
   "source": [
    "max_length = 140\n",
    "train_word_sequences = pad_sequences(word_sequences[:6000], maxlen=max_length, padding='post')\n",
    "test_word_sequences = pad_sequences(word_sequences[6000:7000], maxlen=max_length, padding='post')\n",
    "sub_word_sequences = pad_sequences(word_sequences[7000:], maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1T85TdKpPO31"
   },
   "source": [
    "# embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNOkElT1PSjf"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVqYxRFPPWOM"
   },
   "outputs": [],
   "source": [
    "EMB_DIM = 300\n",
    "\n",
    "w2v = Word2Vec(sentences, size = EMB_DIM, window = 5, min_count = 5, negative = 15, iter = 10, workers = multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KjgvWDvmPWWN"
   },
   "outputs": [],
   "source": [
    "word_vector = w2v.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IKJTto3PiKee"
   },
   "source": [
    "# glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 389872,
     "status": "ok",
     "timestamp": 1577959910475,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "UBewf9W2iJoO",
    "outputId": "072c7238-59ba-49f1-db94-bc3cee9e2dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-02 10:05:21--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2020-01-02 10:05:21--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2020-01-02 10:05:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  2.09MB/s    in 6m 28s  \n",
      "\n",
      "2020-01-02 10:11:49 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 411110,
     "status": "ok",
     "timestamp": 1577959934453,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "hqJ8gs5Hix-p",
    "outputId": "8002976f-f5bd-4198-d19c-877e014162ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.50d.txt        \n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n"
     ]
    }
   ],
   "source": [
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2800,
     "status": "ok",
     "timestamp": 1576499204390,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "b3AEnMHJrLvu",
    "outputId": "43d052ea-8cfc-4cfc-f5c2-ceb4ccfe5c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-16 12:26:42--  https://github.com/facebookresearch/fastText/archive/0.2.0.zip\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://codeload.github.com/facebookresearch/fastText/zip/0.2.0 [following]\n",
      "--2019-12-16 12:26:42--  https://codeload.github.com/facebookresearch/fastText/zip/0.2.0\n",
      "Resolving codeload.github.com (codeload.github.com)... 192.30.255.120\n",
      "Connecting to codeload.github.com (codeload.github.com)|192.30.255.120|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘0.2.0.zip’\n",
      "\n",
      "0.2.0.zip               [  <=>               ]   4.10M  12.5MB/s    in 0.3s    \n",
      "\n",
      "2019-12-16 12:26:43 (12.5 MB/s) - ‘0.2.0.zip’ saved [4304799]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/facebookresearch/fastText/archive/0.2.0.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJtDrZXjn5ZL"
   },
   "outputs": [],
   "source": [
    "def load_glove(word_dict, lemma_dict):\n",
    "    EMBEDDING_FILE = 'glove.6B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    embed_size = 300\n",
    "    nb_words = len(word_dict)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
    "    print(unknown_vector[:5])\n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lemma_dict[key]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \"\"\"\n",
    "        if len(key) > 1:\n",
    "            word = correction(key)\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[word_dict[key]] = embedding_vector\n",
    "                continue\n",
    "        \"\"\"\n",
    "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
    "    return embedding_matrix, nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLJsCcTV08uG"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31528,
     "status": "ok",
     "timestamp": 1577959995609,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "hyf80Ty1n5lG",
    "outputId": "3d2fa639-0c06-41d6-cca8-5b776944aedb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 11594/50642 [00:00<00:00, 115903.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50642/50642 [00:01<00:00, 48167.71it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_glove, nb_words = load_glove(word_dict, lemma_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AU6oYWa9q42B"
   },
   "source": [
    "# load fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "krTr8WR7q_Wf"
   },
   "outputs": [],
   "source": [
    "def load_fasttext(word_dict, lemma_dict):\n",
    "    EMBEDDING_FILE = 'fast/wiki-news-300d-1M.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "    embed_size = 300\n",
    "    nb_words = len(word_dict)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
    "    print(unknown_vector[:5])\n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lemma_dict[key]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        \"\"\"\n",
    "        if len(key) > 1:\n",
    "            word = correction(key)\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[word_dict[key]] = embedding_vector\n",
    "                continue\n",
    "        \"\"\"\n",
    "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
    "    return embedding_matrix, nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64781,
     "status": "ok",
     "timestamp": 1576514093346,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "sVrDLng0jq1a",
    "outputId": "0d388c3c-7c9c-43fb-e4f1-969d15211a2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 18138/61476 [00:00<00:00, 181353.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61476/61476 [00:00<00:00, 91733.15it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix_fasttext, nb_words = load_fasttext(word_dict, lemma_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1451,
     "status": "ok",
     "timestamp": 1576514197454,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "4qg-qbmnkVvl",
    "outputId": "0bec36b9-e4a6-4b90-adb2-0822be2208af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61477, 300), (61477, 300), (61477, 600))"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.concatenate((embedding_matrix_glove, embedding_matrix_fasttext), axis=1)\n",
    "embedding_matrix_glove.shape, embedding_matrix_fasttext.shape, embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIS6MyJ6ku-R"
   },
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix_glove\n",
    "embedding_dim = 300\n",
    "vocab_size = 50643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1577717311396,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "hXYMu6ZlR5bY",
    "outputId": "33db0957-a858-43f8-a94c-f0e7f21ebe82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50643, 300)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N7QVjLd-P1q8"
   },
   "source": [
    "# load embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27392,
     "status": "ok",
     "timestamp": 1575876964187,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "yOEfQXhoP4Eh",
    "outputId": "ec649b72-17da-4272-ffbc-4d33aa3bb6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400,000 word vectors in glove.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {} # We create a dictionary of word -> embedding\n",
    "\n",
    "with open('glove.6B.300d.txt') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0] # The first value is the word, the rest are the values of the embedding\n",
    "        embedding = np.asarray(values[1:], dtype='float32') # Load embedding\n",
    "        embeddings_index[word] = embedding # Add embedding to our embedding dictionary\n",
    "\n",
    "\n",
    "print('Found {:,} word vectors in glove.'.format(len(embeddings_index)))\n",
    "\n",
    "embedding_dim = 300 # We use 100 dimensional glove vectors\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(vocab_size, len(word_index)) # How many words are there actually\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embedding_dim))\n",
    "\n",
    "# The vectors need to be in the same position as their index. \n",
    "# Meaning a word with token 1 needs to be in the second row (rows start with zero) and so on\n",
    "\n",
    "# Loop over all words in the word index\n",
    "for word, i in word_index.items():\n",
    "    # If we are above the amount of words we want to use we do nothing\n",
    "    if i >= vocab_size: \n",
    "        continue\n",
    "    # Get the embedding vector for the word\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    # If there is an embedding vector, put it in the embedding matrix\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Du6Rf6SfQDtV"
   },
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Cek8SNiB294"
   },
   "outputs": [],
   "source": [
    "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    file_path = \"best_model.h5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "    \n",
    "    inp = Input(shape = (max_length,))\n",
    "    xc = Embedding(vocab_size, embedding_dim, input_length=max_length, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    xc = SpatialDropout1D(spatial_dr)(xc)\n",
    "\n",
    "    gru = Bidirectional(GRU(units, return_sequences = True))(xc)\n",
    "    lstm = Bidirectional(LSTM(units, return_sequences = True))(xc)\n",
    "   \n",
    "    x = concatenate([gru, lstm])\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 4), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 8), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 16), activation='relu') (x))\n",
    "    x = Dense(4, activation = \"sigmoid\")(x)\n",
    "    print(x.shape)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = ['accuracy'])\n",
    "    model.fit(train_word_sequences, np.array(data[:6000][['THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']]), batch_size = 128, epochs = 200, shuffle = True, validation_split=0.1, verbose = 1, callbacks = [check_point, early_stop])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2JsOi6KNRf3"
   },
   "outputs": [],
   "source": [
    "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    file_path = \"best_model.h5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "    \n",
    "    inp = Input(shape = (max_length,))\n",
    "    xc = Embedding(vocab_size, embedding_dim, input_length=max_length, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    xc = SpatialDropout1D(spatial_dr)(xc)\n",
    "\n",
    "    gru = Bidirectional(GRU(units, return_sequences = True))(xc)\n",
    "    lstm = Bidirectional(LSTM(units, return_sequences = True))(xc)\n",
    "\n",
    "    max_pool_gru = GlobalMaxPooling1D()(gru)\n",
    "    max_pool_lstm = GlobalMaxPooling1D()(lstm)\n",
    "   \n",
    "    x = concatenate([max_pool_gru, max_pool_lstm])\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 4), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 8), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 16), activation='relu') (x))\n",
    "    x = Dense(4, activation = \"sigmoid\")(x)\n",
    "    print(x.shape)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = ['accuracy'])\n",
    "    model.fit(train_word_sequences, np.array(data[:6000][['THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']]), batch_size = 128, epochs = 200, shuffle = True, validation_split=0.1, verbose = 1, callbacks = [check_point, early_stop])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fyLnvvJQCCH"
   },
   "outputs": [],
   "source": [
    "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    file_path = \"best_model.h5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "    \n",
    "    inp = Input(shape = (max_length,))\n",
    "    xc = Embedding(vocab_size, embedding_dim, input_length=max_length, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    xc = SpatialDropout1D(spatial_dr)(xc)\n",
    "\n",
    "    x1 = Conv1D(conv_size, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(xc)\n",
    "    avg_pool1_gru = Bidirectional(GRU(units, return_sequences = True))(x1)\n",
    "    #max_pool1_gru = Bidirectional(LSTM(units, return_sequences = True))(x1)\n",
    "    \n",
    "    #avg_pool1_gru = SpatialDropout1D(spatial_dr)(avg_pool1_gru)\n",
    "    #max_pool1_gru = SpatialDropout1D(spatial_dr)(max_pool1_gru)\n",
    "    #x = concatenate([avg_pool1_gru, max_pool1_gru,])\n",
    "    x = Flatten()(avg_pool1_gru)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 4), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 8), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 16), activation='relu') (x))\n",
    "    x = Dense(4, activation = \"sigmoid\")(x)\n",
    "    print(x.shape)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = ['accuracy'])\n",
    "    model.fit(train_word_sequences, np.array(data[:6000][['THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']]), batch_size = 128, epochs = 200, shuffle = True, validation_split=0.1, verbose = 1, callbacks = [check_point, early_stop])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "blvs_S1wZeyd"
   },
   "outputs": [],
   "source": [
    "def build_model1(lr=0.0, lr_d=0.0, units=0, spatial_dr=0.0, kernel_size1=3, kernel_size2=2, dense_units=128, dr=0.1, conv_size=32):\n",
    "    file_path = \"best_model.h5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n",
    "                                  save_best_only = True, mode = \"min\")\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "    \n",
    "    inp = Input(shape = (max_length,))\n",
    "    x = Embedding(vocab_size, embedding_dim, input_length=max_length, weights = [embedding_matrix], trainable = False)(inp)\n",
    "    x1 = SpatialDropout1D(spatial_dr)(x)\n",
    "\n",
    "    #x_gru = Bidirectional(GRU(units, return_sequences = True))(x1)\n",
    "    x1 = Conv1D(conv_size, kernel_size=4, padding='valid', kernel_initializer='he_uniform')(x1)\n",
    "    avg_pool1_gru = GlobalAveragePooling1D()(x1)\n",
    "    max_pool1_gru = GlobalMaxPooling1D()(x1)\n",
    "    \n",
    "    x = concatenate([avg_pool1_gru, max_pool1_gru])\n",
    "    print(x.shape)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(dense_units, activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 2), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 4), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 8), activation='relu') (x))\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dr)(Dense(int(dense_units / 16), activation='relu') (x))\n",
    "    x = Dense(4, activation = \"sigmoid\")(x)\n",
    "    model = Model(inputs = inp, outputs = x)\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = ['accuracy'])\n",
    "    model.fit(train_word_sequences, np.array(data[:6000][['THEORETICAL','ENGINEERING','EMPIRICAL','OTHERS']]), batch_size = 128, epochs = 200, shuffle = True, validation_split=0.1, verbose = 1, callbacks = [check_point, early_stop])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1327660,
     "status": "ok",
     "timestamp": 1577973283189,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "HVa3UzhtQL7A",
    "outputId": "ac85d872-6cbc-4fdf-9d21-05c18be11ca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4)\n",
      "Train on 5400 samples, validate on 600 samples\n",
      "Epoch 1/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.7838 - acc: 0.5381\n",
      "Epoch 00001: val_loss improved from inf to 0.67258, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 69s 13ms/sample - loss: 0.7841 - acc: 0.5380 - val_loss: 0.6726 - val_acc: 0.6650\n",
      "Epoch 2/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.7500 - acc: 0.5564\n",
      "Epoch 00002: val_loss improved from 0.67258 to 0.64701, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.7498 - acc: 0.5566 - val_loss: 0.6470 - val_acc: 0.6696\n",
      "Epoch 3/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.7289 - acc: 0.5722\n",
      "Epoch 00003: val_loss improved from 0.64701 to 0.62388, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.7288 - acc: 0.5721 - val_loss: 0.6239 - val_acc: 0.6696\n",
      "Epoch 4/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.7091 - acc: 0.5852\n",
      "Epoch 00004: val_loss improved from 0.62388 to 0.60625, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.7089 - acc: 0.5853 - val_loss: 0.6062 - val_acc: 0.6867\n",
      "Epoch 5/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6903 - acc: 0.6065\n",
      "Epoch 00005: val_loss improved from 0.60625 to 0.59201, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.6900 - acc: 0.6067 - val_loss: 0.5920 - val_acc: 0.6900\n",
      "Epoch 6/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6722 - acc: 0.6184\n",
      "Epoch 00006: val_loss improved from 0.59201 to 0.57742, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.6720 - acc: 0.6186 - val_loss: 0.5774 - val_acc: 0.7029\n",
      "Epoch 7/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6500 - acc: 0.6409\n",
      "Epoch 00007: val_loss improved from 0.57742 to 0.56393, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.6504 - acc: 0.6405 - val_loss: 0.5639 - val_acc: 0.7150\n",
      "Epoch 8/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6427 - acc: 0.6405\n",
      "Epoch 00008: val_loss improved from 0.56393 to 0.54815, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.6430 - acc: 0.6404 - val_loss: 0.5481 - val_acc: 0.7233\n",
      "Epoch 9/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6288 - acc: 0.6558\n",
      "Epoch 00009: val_loss improved from 0.54815 to 0.53350, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.6286 - acc: 0.6560 - val_loss: 0.5335 - val_acc: 0.7379\n",
      "Epoch 10/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.6689\n",
      "Epoch 00010: val_loss improved from 0.53350 to 0.52091, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.6086 - acc: 0.6689 - val_loss: 0.5209 - val_acc: 0.7483\n",
      "Epoch 11/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.6826\n",
      "Epoch 00011: val_loss improved from 0.52091 to 0.50950, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5997 - acc: 0.6825 - val_loss: 0.5095 - val_acc: 0.7567\n",
      "Epoch 12/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5905 - acc: 0.6871\n",
      "Epoch 00012: val_loss improved from 0.50950 to 0.50024, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5912 - acc: 0.6864 - val_loss: 0.5002 - val_acc: 0.7554\n",
      "Epoch 13/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.6952\n",
      "Epoch 00013: val_loss improved from 0.50024 to 0.49474, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5826 - acc: 0.6951 - val_loss: 0.4947 - val_acc: 0.7538\n",
      "Epoch 14/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5732 - acc: 0.7000\n",
      "Epoch 00014: val_loss improved from 0.49474 to 0.48899, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5737 - acc: 0.6998 - val_loss: 0.4890 - val_acc: 0.7613\n",
      "Epoch 15/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5697 - acc: 0.7032\n",
      "Epoch 00015: val_loss improved from 0.48899 to 0.48451, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5698 - acc: 0.7031 - val_loss: 0.4845 - val_acc: 0.7625\n",
      "Epoch 16/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.7122\n",
      "Epoch 00016: val_loss improved from 0.48451 to 0.48163, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5578 - acc: 0.7122 - val_loss: 0.4816 - val_acc: 0.7638\n",
      "Epoch 17/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.7125\n",
      "Epoch 00017: val_loss improved from 0.48163 to 0.47847, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5540 - acc: 0.7125 - val_loss: 0.4785 - val_acc: 0.7613\n",
      "Epoch 18/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.7198\n",
      "Epoch 00018: val_loss improved from 0.47847 to 0.47622, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5459 - acc: 0.7200 - val_loss: 0.4762 - val_acc: 0.7650\n",
      "Epoch 19/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5378 - acc: 0.7223\n",
      "Epoch 00019: val_loss improved from 0.47622 to 0.47387, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5381 - acc: 0.7222 - val_loss: 0.4739 - val_acc: 0.7621\n",
      "Epoch 20/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5380 - acc: 0.7251\n",
      "Epoch 00020: val_loss improved from 0.47387 to 0.47277, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 6ms/sample - loss: 0.5379 - acc: 0.7251 - val_loss: 0.4728 - val_acc: 0.7638\n",
      "Epoch 21/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5316 - acc: 0.7297\n",
      "Epoch 00021: val_loss improved from 0.47277 to 0.47141, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5318 - acc: 0.7293 - val_loss: 0.4714 - val_acc: 0.7633\n",
      "Epoch 22/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.7301\n",
      "Epoch 00022: val_loss improved from 0.47141 to 0.46877, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5285 - acc: 0.7301 - val_loss: 0.4688 - val_acc: 0.7667\n",
      "Epoch 23/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.7356\n",
      "Epoch 00023: val_loss did not improve from 0.46877\n",
      "5400/5400 [==============================] - 35s 6ms/sample - loss: 0.5199 - acc: 0.7360 - val_loss: 0.4696 - val_acc: 0.7642\n",
      "Epoch 24/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.7426\n",
      "Epoch 00024: val_loss improved from 0.46877 to 0.46819, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5115 - acc: 0.7426 - val_loss: 0.4682 - val_acc: 0.7663\n",
      "Epoch 25/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5122 - acc: 0.7422\n",
      "Epoch 00025: val_loss improved from 0.46819 to 0.46711, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5122 - acc: 0.7423 - val_loss: 0.4671 - val_acc: 0.7688\n",
      "Epoch 26/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5067 - acc: 0.7489\n",
      "Epoch 00026: val_loss improved from 0.46711 to 0.46613, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.5067 - acc: 0.7491 - val_loss: 0.4661 - val_acc: 0.7733\n",
      "Epoch 27/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.7488\n",
      "Epoch 00027: val_loss improved from 0.46613 to 0.46465, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 35s 7ms/sample - loss: 0.5051 - acc: 0.7489 - val_loss: 0.4646 - val_acc: 0.7700\n",
      "Epoch 28/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.5001 - acc: 0.7501\n",
      "Epoch 00028: val_loss did not improve from 0.46465\n",
      "5400/5400 [==============================] - 35s 6ms/sample - loss: 0.5000 - acc: 0.7502 - val_loss: 0.4662 - val_acc: 0.7704\n",
      "Epoch 29/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.7481\n",
      "Epoch 00029: val_loss did not improve from 0.46465\n",
      "5400/5400 [==============================] - 35s 6ms/sample - loss: 0.4992 - acc: 0.7482 - val_loss: 0.4660 - val_acc: 0.7679\n",
      "Epoch 30/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.7535\n",
      "Epoch 00030: val_loss did not improve from 0.46465\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4928 - acc: 0.7537 - val_loss: 0.4650 - val_acc: 0.7688\n",
      "Epoch 31/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.7586\n",
      "Epoch 00031: val_loss improved from 0.46465 to 0.46458, saving model to best_model.h5\n",
      "5400/5400 [==============================] - 36s 7ms/sample - loss: 0.4894 - acc: 0.7588 - val_loss: 0.4646 - val_acc: 0.7713\n",
      "Epoch 32/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4803 - acc: 0.7634\n",
      "Epoch 00032: val_loss did not improve from 0.46458\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4802 - acc: 0.7634 - val_loss: 0.4647 - val_acc: 0.7704\n",
      "Epoch 33/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.7633\n",
      "Epoch 00033: val_loss did not improve from 0.46458\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4787 - acc: 0.7633 - val_loss: 0.4657 - val_acc: 0.7617\n",
      "Epoch 34/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4794 - acc: 0.7643\n",
      "Epoch 00034: val_loss did not improve from 0.46458\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4793 - acc: 0.7644 - val_loss: 0.4671 - val_acc: 0.7629\n",
      "Epoch 35/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4721 - acc: 0.7644\n",
      "Epoch 00035: val_loss did not improve from 0.46458\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4726 - acc: 0.7640 - val_loss: 0.4663 - val_acc: 0.7642\n",
      "Epoch 36/200\n",
      "5376/5400 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.7723\n",
      "Epoch 00036: val_loss did not improve from 0.46458\n",
      "5400/5400 [==============================] - 34s 6ms/sample - loss: 0.4696 - acc: 0.7724 - val_loss: 0.4676 - val_acc: 0.7646\n"
     ]
    }
   ],
   "source": [
    "model1 = build_model1(lr = 1e-4, lr_d = 1e-7, units = 256, spatial_dr = 0.5, kernel_size1=3, kernel_size2=2, dense_units=512, dr=0.3, conv_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1940,
     "status": "ok",
     "timestamp": 1577719341614,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "CuM_GELfSEal",
    "outputId": "c3c29dbf-c0a0-4ba6-ed35-147df034f1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model.h5  glove.6B.100d.txt  glove.6B.300d.txt  glove.6B.zip\n",
      "data.csv       glove.6B.200d.txt  glove.6B.50d.txt   sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 668
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38947,
     "status": "error",
     "timestamp": 1577974994794,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "g9E9b-eSSXSi",
    "outputId": "47849333-2212-46ff-9c7b-e74f42a4ba3d"
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_Placeholder_798_0_11}}]]\n\t [[ReadVariableOp_830/_11399]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_Placeholder_798_0_11}}]]\n0 successful operations.\n0 derived errors ignored.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-343ff32b992f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_word_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    141\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    142\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    188\u001b[0m           \u001b[0moptimizer_weight_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_optimizer_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_weight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             logging.warning('Error in loading the saved optimizer '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_vars\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    762\u001b[0m                          \"provided weight shape \" + str(w.shape))\n\u001b[1;32m    763\u001b[0m       \u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m   def add_weight(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3257\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3258\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3259\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1384\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: 2 root error(s) found.\n  (0) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_Placeholder_798_0_11}}]]\n\t [[ReadVariableOp_830/_11399]]\n  (1) Internal: Dst tensor is not initialized.\n\t [[{{node _arg_Placeholder_798_0_11}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model1 = load_model('best_model.h5')\n",
    "pred1 = model1.predict(test_word_sequences, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2162,
     "status": "ok",
     "timestamp": 1577889683036,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "9Fc6PAFXdPRI",
    "outputId": "175dc51c-8b9e-46dc-d5ce-19fb25481ba3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADLCAYAAACVv9NEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFMS7DtoHyG2AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.array(list(pred1))\n",
    "a = y[:,0]\n",
    "b = y[:,1]\n",
    "c = y[:,2]\n",
    "d = y[:,3]\n",
    "\n",
    "import seaborn as sns\n",
    "plt.subplot(5,1,1)\n",
    "sns.distplot(a, bins=20, kde=False, rug=True);\n",
    "plt.subplot(5,1,2)\n",
    "sns.distplot(b, bins=20, kde=False, rug=True);\n",
    "plt.subplot(5,1,3)\n",
    "sns.distplot(c, bins=20, kde=False, rug=True);\n",
    "plt.subplot(5,1,4)\n",
    "sns.distplot(d, bins=20, kde=False, rug=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9i82e_BFaGSq"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46005,
     "status": "ok",
     "timestamp": 1577971284317,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "OHQW5wMsIUYn",
    "outputId": "a53c60a1-697a-4432-fdd7-c62d8415427c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7069351230425057 0.5690000000000001\n",
      "0.7317073170731708 0.38\n",
      "0.5696670776818743 0.24\n",
      "0.21739130434782608 0.253\n"
     ]
    }
   ],
   "source": [
    "#lstm\n",
    "#pred = pred3 + pred4 + pred5\n",
    "th1 = 0\n",
    "th2 = 0\n",
    "th3 = 0\n",
    "th4 = 0\n",
    "max1 = 0\n",
    "max2 = 0\n",
    "max3 = 0\n",
    "max4 = 0\n",
    "for thre in range(1000):\n",
    "    y = np.array(list(pred1))\n",
    "    a = y[:,0]\n",
    "    b = y[:,1]\n",
    "    c = y[:,2]\n",
    "    d = y[:,3]\n",
    "    for i in range(1000):\n",
    "        if a[i] > thre*0.001:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "        if b[i] > thre*0.001:\n",
    "            b[i] = 1\n",
    "        else:\n",
    "            b[i] = 0\n",
    "        if c[i] > thre*0.001:\n",
    "            c[i] = 1\n",
    "        else:\n",
    "            c[i] = 0\n",
    "        if d[i] > thre*0.001:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] = 0\n",
    "    if max1 < f1_score(a, data['THEORETICAL'][6000:7000]):\n",
    "        max1 = f1_score(a, data['THEORETICAL'][6000:7000])\n",
    "        th1 = thre*0.001\n",
    "    if max2 < f1_score(b, data['ENGINEERING'][6000:7000]):\n",
    "        max2 = f1_score(b, data['ENGINEERING'][6000:7000])\n",
    "        th2 = thre*0.001\n",
    "    if max3 < f1_score(c, data['EMPIRICAL'][6000:7000]):\n",
    "        max3 = f1_score(c, data['EMPIRICAL'][6000:7000])\n",
    "        th3 = thre*0.001\n",
    "    if max4 < f1_score(d, data['OTHERS'][6000:7000]):\n",
    "        max4 = f1_score(d, data['OTHERS'][6000:7000])\n",
    "        th4 = thre*0.001\n",
    "                       \n",
    "print(max1, th1)\n",
    "print(max2, th2)\n",
    "print(max3, th3)\n",
    "print(max4, th4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 676,
     "status": "ok",
     "timestamp": 1577971290276,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "wwOO5tohIbcU",
    "outputId": "05764003-ce4a-4679-98c0-44676d2fdbbe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6634974533106961"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lstm\n",
    "y = np.array(list(pred1))\n",
    "a = y[:,0].tolist()\n",
    "b = y[:,1].tolist()\n",
    "c = y[:,2].tolist()\n",
    "d = y[:,3].tolist()\n",
    "for i in range(1000):\n",
    "  if a[i] > th1:\n",
    "    a[i] = 1\n",
    "  else:\n",
    "    a[i] = 0\n",
    "  if b[i] > th2:\n",
    "    b[i] = 1\n",
    "  else:\n",
    "    b[i] = 0\n",
    "  if c[i] > th3:\n",
    "    c[i] = 1\n",
    "  else:\n",
    "    c[i] = 0\n",
    "  if d[i] > th4:\n",
    "    d[i] = 1\n",
    "  else:\n",
    "    d[i] = 0\n",
    "a = a + b + c + d\n",
    "ans = data['THEORETICAL'][6000:7000].tolist()\n",
    "ans = ans + data['ENGINEERING'][6000:7000].tolist() + data['EMPIRICAL'][6000:7000].tolist() + data['OTHERS'][6000:7000].tolist()\n",
    "f1_score(a, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17643,
     "status": "ok",
     "timestamp": 1577964379824,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "5jZjDclIYiBT",
    "outputId": "563ddeac-b810-4fdf-bab2-6dd31c459414"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7257019438444925 0.41500000000000004\n",
      "0.7171875 0.193\n",
      "0.5681818181818182 0.401\n",
      "0.1935483870967742 0.256\n"
     ]
    }
   ],
   "source": [
    "#Bi-directional RNN + pooling layer\n",
    "#pred = pred3 + pred4 + pred5\n",
    "th1 = 0\n",
    "th2 = 0\n",
    "th3 = 0\n",
    "th4 = 0\n",
    "max1 = 0\n",
    "max2 = 0\n",
    "max3 = 0\n",
    "max4 = 0\n",
    "for thre in range(1000):\n",
    "    y = np.array(list(pred1))\n",
    "    a = y[:,0]\n",
    "    b = y[:,1]\n",
    "    c = y[:,2]\n",
    "    d = y[:,3]\n",
    "    for i in range(1000):\n",
    "        if a[i] > thre*0.001:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "        if b[i] > thre*0.001:\n",
    "            b[i] = 1\n",
    "        else:\n",
    "            b[i] = 0\n",
    "        if c[i] > thre*0.001:\n",
    "            c[i] = 1\n",
    "        else:\n",
    "            c[i] = 0\n",
    "        if d[i] > thre*0.001:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] = 0\n",
    "    if max1 < f1_score(a, data['THEORETICAL'][6000:7000]):\n",
    "        max1 = f1_score(a, data['THEORETICAL'][6000:7000])\n",
    "        th1 = thre*0.001\n",
    "    if max2 < f1_score(b, data['ENGINEERING'][6000:7000]):\n",
    "        max2 = f1_score(b, data['ENGINEERING'][6000:7000])\n",
    "        th2 = thre*0.001\n",
    "    if max3 < f1_score(c, data['EMPIRICAL'][6000:7000]):\n",
    "        max3 = f1_score(c, data['EMPIRICAL'][6000:7000])\n",
    "        th3 = thre*0.001\n",
    "    if max4 < f1_score(d, data['OTHERS'][6000:7000]):\n",
    "        max4 = f1_score(d, data['OTHERS'][6000:7000])\n",
    "        th4 = thre*0.001\n",
    "                       \n",
    "print(max1, th1)\n",
    "print(max2, th2)\n",
    "print(max3, th3)\n",
    "print(max4, th4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1577964389750,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "4JgbH0P6ADba",
    "outputId": "2b08b116-8ace-4a5d-b771-aa3c85af5251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6686646686646686"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bi-directional RNN + pooling layer\n",
    "y = np.array(list(pred1))\n",
    "a = y[:,0].tolist()\n",
    "b = y[:,1].tolist()\n",
    "c = y[:,2].tolist()\n",
    "d = y[:,3].tolist()\n",
    "for i in range(1000):\n",
    "  if a[i] > th1:\n",
    "    a[i] = 1\n",
    "  else:\n",
    "    a[i] = 0\n",
    "  if b[i] > th2:\n",
    "    b[i] = 1\n",
    "  else:\n",
    "    b[i] = 0\n",
    "  if c[i] > th3:\n",
    "    c[i] = 1\n",
    "  else:\n",
    "    c[i] = 0\n",
    "  if d[i] > th4:\n",
    "    d[i] = 1\n",
    "  else:\n",
    "    d[i] = 0\n",
    "a = a + b + c + d\n",
    "ans = data['THEORETICAL'][6000:7000].tolist()\n",
    "ans = ans + data['ENGINEERING'][6000:7000].tolist() + data['EMPIRICAL'][6000:7000].tolist() + data['OTHERS'][6000:7000].tolist()\n",
    "f1_score(a, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17739,
     "status": "ok",
     "timestamp": 1577968871563,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "N7dbcDdI6nrQ",
    "outputId": "c8a8e8e8-152a-45fc-cf7b-dc8e664f65ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.727854855923159 0.384\n",
      "0.726094003241491 0.314\n",
      "0.5501066098081023 0.279\n",
      "0.21052631578947367 0.164\n"
     ]
    }
   ],
   "source": [
    "# CNN + pooling \n",
    "th1 = 0\n",
    "th2 = 0\n",
    "th3 = 0\n",
    "th4 = 0\n",
    "max1 = 0\n",
    "max2 = 0\n",
    "max3 = 0\n",
    "max4 = 0\n",
    "for thre in range(1000):\n",
    "    y = np.array(list(pred1))\n",
    "    a = y[:,0]\n",
    "    b = y[:,1]\n",
    "    c = y[:,2]\n",
    "    d = y[:,3]\n",
    "    for i in range(1000):\n",
    "        if a[i] > thre*0.001:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "        if b[i] > thre*0.001:\n",
    "            b[i] = 1\n",
    "        else:\n",
    "            b[i] = 0\n",
    "        if c[i] > thre*0.001:\n",
    "            c[i] = 1\n",
    "        else:\n",
    "            c[i] = 0\n",
    "        if d[i] > thre*0.001:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] = 0\n",
    "    if max1 < f1_score(a, data['THEORETICAL'][6000:7000]):\n",
    "        max1 = f1_score(a, data['THEORETICAL'][6000:7000])\n",
    "        th1 = thre*0.001\n",
    "    if max2 < f1_score(b, data['ENGINEERING'][6000:7000]):\n",
    "        max2 = f1_score(b, data['ENGINEERING'][6000:7000])\n",
    "        th2 = thre*0.001\n",
    "    if max3 < f1_score(c, data['EMPIRICAL'][6000:7000]):\n",
    "        max3 = f1_score(c, data['EMPIRICAL'][6000:7000])\n",
    "        th3 = thre*0.001\n",
    "    if max4 < f1_score(d, data['OTHERS'][6000:7000]):\n",
    "        max4 = f1_score(d, data['OTHERS'][6000:7000])\n",
    "        th4 = thre*0.001\n",
    "                       \n",
    "print(max1, th1)\n",
    "print(max2, th2)\n",
    "print(max3, th3)\n",
    "print(max4, th4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1577968879831,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "TIepUFggw-YT",
    "outputId": "d1f92ffb-93f7-4549-b15c-1213697cc778"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6571517219981383"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CNN + pooling\n",
    "y = np.array(list(pred1))\n",
    "a = y[:,0].tolist()\n",
    "b = y[:,1].tolist()\n",
    "c = y[:,2].tolist()\n",
    "d = y[:,3].tolist()\n",
    "for i in range(1000):\n",
    "  if a[i] > th1:\n",
    "    a[i] = 1\n",
    "  else:\n",
    "    a[i] = 0\n",
    "  if b[i] > th2:\n",
    "    b[i] = 1\n",
    "  else:\n",
    "    b[i] = 0\n",
    "  if c[i] > th3:\n",
    "    c[i] = 1\n",
    "  else:\n",
    "    c[i] = 0\n",
    "  if d[i] > th4:\n",
    "    d[i] = 1\n",
    "  else:\n",
    "    d[i] = 0\n",
    "a = a + b + c + d\n",
    "ans = data['THEORETICAL'][6000:7000].tolist()\n",
    "ans = ans + data['ENGINEERING'][6000:7000].tolist() + data['EMPIRICAL'][6000:7000].tolist() + data['OTHERS'][6000:7000].tolist()\n",
    "f1_score(a, ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 670,
     "status": "ok",
     "timestamp": 1577961046568,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "S3A8vNl4zDdj",
    "outputId": "8d90f9ad-335d-4e42-a355-0dceb4ecd4d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1001"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17612,
     "status": "ok",
     "timestamp": 1577967755554,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "ZdZZy_WxzOw2",
    "outputId": "bb127bcd-cd7c-4e86-d630-1524d5c0b9a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7093712930011864 0.429\n",
      "0.7222222222222223 0.41100000000000003\n",
      "0.555045871559633 0.259\n",
      "0.1904761904761905 0.124\n"
     ]
    }
   ],
   "source": [
    "#CNN - pooling + RNN\n",
    "th1 = 0\n",
    "th2 = 0\n",
    "th3 = 0\n",
    "th4 = 0\n",
    "max1 = 0\n",
    "max2 = 0\n",
    "max3 = 0\n",
    "max4 = 0\n",
    "for thre in range(1000):\n",
    "    y = np.array(list(pred1))\n",
    "    a = y[:,0]\n",
    "    b = y[:,1]\n",
    "    c = y[:,2]\n",
    "    d = y[:,3]\n",
    "    for i in range(1000):\n",
    "        if a[i] > thre*0.001:\n",
    "            a[i] = 1\n",
    "        else:\n",
    "            a[i] = 0\n",
    "        if b[i] > thre*0.001:\n",
    "            b[i] = 1\n",
    "        else:\n",
    "            b[i] = 0\n",
    "        if c[i] > thre*0.001:\n",
    "            c[i] = 1\n",
    "        else:\n",
    "            c[i] = 0\n",
    "        if d[i] > thre*0.001:\n",
    "            d[i] = 1\n",
    "        else:\n",
    "            d[i] = 0\n",
    "    if max1 < f1_score(a, data['THEORETICAL'][6000:7000]):\n",
    "        max1 = f1_score(a, data['THEORETICAL'][6000:7000])\n",
    "        th1 = thre*0.001\n",
    "    if max2 < f1_score(b, data['ENGINEERING'][6000:7000]):\n",
    "        max2 = f1_score(b, data['ENGINEERING'][6000:7000])\n",
    "        th2 = thre*0.001\n",
    "    if max3 < f1_score(c, data['EMPIRICAL'][6000:7000]):\n",
    "        max3 = f1_score(c, data['EMPIRICAL'][6000:7000])\n",
    "        th3 = thre*0.001\n",
    "    if max4 < f1_score(d, data['OTHERS'][6000:7000]):\n",
    "        max4 = f1_score(d, data['OTHERS'][6000:7000])\n",
    "        th4 = thre*0.001\n",
    "                       \n",
    "print(max1, th1)\n",
    "print(max2, th2)\n",
    "print(max3, th3)\n",
    "print(max4, th4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1577967766131,
     "user": {
      "displayName": "Shih Zach",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mD4GhERm4cN2z-w7b5g9uAPNOrWLZeMcx1StTIzMw=s64",
      "userId": "14273486237821822591"
     },
     "user_tz": -480
    },
    "id": "l-OV60xu4NuP",
    "outputId": "70c6aff1-28f7-4fd9-fd32-4ce3fd946c2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6596445029624753"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN - pooling + RNN\n",
    "y = np.array(list(pred1))\n",
    "a = y[:,0].tolist()\n",
    "b = y[:,1].tolist()\n",
    "c = y[:,2].tolist()\n",
    "d = y[:,3].tolist()\n",
    "for i in range(1000):\n",
    "  if a[i] > th1:\n",
    "    a[i] = 1\n",
    "  else:\n",
    "    a[i] = 0\n",
    "  if b[i] > th2:\n",
    "    b[i] = 1\n",
    "  else:\n",
    "    b[i] = 0\n",
    "  if c[i] > th3:\n",
    "    c[i] = 1\n",
    "  else:\n",
    "    c[i] = 0\n",
    "  if d[i] > th4:\n",
    "    d[i] = 1\n",
    "  else:\n",
    "    d[i] = 0\n",
    "a = a + b + c + d\n",
    "ans = data['THEORETICAL'][6000:7000].tolist()\n",
    "ans = ans + data['ENGINEERING'][6000:7000].tolist() + data['EMPIRICAL'][6000:7000].tolist() + data['OTHERS'][6000:7000].tolist()\n",
    "f1_score(a, ans)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "1T85TdKpPO31",
    "N7QVjLd-P1q8"
   ],
   "machine_shape": "hm",
   "name": "embed_w2v.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
